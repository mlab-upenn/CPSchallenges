 \section{Verification of Autonomous Vehicle Planning}

\begin{figure*}
	\centering
	\includegraphics[width=1.8\columnwidth]{Figures/apex_stack}
	\caption{Autonomous vehicle planning stack with a behavioral planner which continually makes decisions. For example, when the decision to change lanes is made, the local planner must find a safe and smooth trajectory to follow around dynamic obstacles whose behavior is not fully known.}
\label{fig:apex_stack}
\vspace{-10pt}
\end{figure*}

  Each year there are an average of 1.24 million traffic fatalities around the world \cite{Waldrop2015}. Estimates indicate that more than 90 percent of all accidents are due to driver error \cite{Waldrop2015}. Competent autonomous vehicles (AVs) could drastically reduce the occurrence of such incidents, but a major question first needs be answered:
  how can we judge when an AV is ready to graduate from research laboratories to public roads?
  One thing is clear: the public will want significant evidence that AVs are indeed safe \cite{weld1994first}. 
  This raises significant ethical and legal questions about how the AV should behave, and technical questions about how to \emph{verify} that it will always behave the way its designers intended.\vspace{4pt}
  
\emph{How do you give a self-driving car a driver's license?}\vspace{4pt}

~Prototype AVs have driven millions of miles and are even being approved for \emph{testing} on public roads in some states \cite{Iozzio2014}; however, manufacturers cannot \emph{verify} (i.e., guarantee) the safety of even the simplest of scenarios in the presence of other dynamic traffic participants. 
  Compounding, the difficultly of vehicle certification, vehicle manufacturers such as Tesla are transitioning to frequent over-the-air software updates. Such practice eschews conventional vehicle development technique and greatly increases pressure on developers to deliver correct software at a rapid pace. 
 
  The net result of the growing pressure to release AVs is a wide gap between current regulations and our technological capabilities. 
  Human drivers are not `certified' to act safely in all situations, in fact, we know they don't; however, they assume liability for their actions.
  Who is liable for the behavior of an AV? 
  Currently, it appears that manufacturers will take one of two approaches: (1) assume liability for the actions of the vehicle and self-insure \cite{volvo15Liability} or (2) force the human occupants of an AV to make all critical decisions and shift liability to the pilot \cite{maurer2015autonomes}. In either case, even if AVs reduce accidents by 99 percent, it is likely that the 1 percent of remaining accidents will invariably spawn a myriad of legal actions against \emph{both} manufacturers \cite{russell2015research} and vehicle owners.   
  If the legal question is not answered, these risks could stifle the development of the AV market.
  
    \begin{figure}[!b]
    	\centering
	\vspace{-10pt}
	\includegraphics[width=\columnwidth]{figures/apex_planning.png}
	\caption{Autonomous vehicle with LiDAR, camera and map data.}
	\label{fig:apex_planning}
\end{figure}

  Thus, regardless of where legal liability falls it is clear that we first need new, practical methods for verification and validation of the decision engines of each AV (as shown in \figref{apex_stack}).
  Furthermore, verification must be automatic, exhaustive, and expedient for clearly defined scenarios. 
  Secondly, ethical considerations still underlie both the design and verification of AVs: how does the safety of the car's passengers weigh against that of people in its environment? 
  Whose morals are embedded in the decision engines of an AV?
  
 \subsection{New and Old Challenges}
 There are several fundamental safety challenges in verifying and implementing autonomous vehicles, including:\begin{enumerate}
\item As shown in \figref{apex_planning}, in a given driving scenario, the vehicleÕs planning controller must determine all possible pathways in the road and provide the supervisory controller with the safest trajectory while interacting with other agents (vehicles, pedestrians, bicyclists), obeying flow control infrastructure (stop signs, traffic lights, environment conditions) and adhering to traffic rules;
\item While the target vehicle is controllable, the state evolutions of other agents are uncertain and the target vehicle must continuously adapt its plan as the scenario evolves;
\item At any time, the driver may interject to take over control of the vehicle.
\end{enumerate} 
Some of the problems facing would-be AV manufacturers in 2016 are very different than those outlined by the teams in the 2007 DARPA Urban Challenge \cite{buehler2009darpa}. One problem highlighted by the first ever crash between AVs at the Urban Challenge \cite{fletcher2008cornell} is that there are no known \quotes{formal methods that would allow definitive statements about the completeness or correctness of a vehicle interacting with a static environment, much less a dynamic one} \cite{urmson2008autonomous}.  Today one must still consider the massive configuration space of each individual snapshot of the day-to-day life of an AV if verification is to be attempted. For example, in order to test the interaction between two 7 DOF AVs requires $10^{14}$ simulations for only 10 samples from each state. If each test takes 10 seconds, the resulting set of simulations will take \emph{30 million years} to complete. Furthermore, within a given scenario, errors in localization, sensing, and actuation imply we never know the state of the world exactly. Small state estimation errors can befuddle motion planning algorithms and mean a difference between collision and safety in tight spots. As many teams in the Urban Challenge noted, a means of verifying the safety of autonomous driving is paramount to putting self-driving cars in the hands of the public \cite{urmson2008autonomous}. 

%% In contrast to the Urban Challenge in 2007, in which only 6 teams out of an original 89 applicants were able to finish, many research labs find themselves in the position of being able to construct a convincing AV in a matter of months; such a vehicle might be relatively competent in 75 percent of the situations it faces, but the long tail of special cases beckons. In fact Sebastian Thrun, a veteran of Google's Self Driving Car project and the Urban Challenge, notes that \emph{there were many more of unusual situations than we believed in the beginning}. One possible solution to handling rare events and scenarios is to record such occurrences using consumer vehicles driving in real traffic; with each new scenario existing behavioral planners can be adjusted via a reinforcement learning scheme \cite{wei2013autonomous, Silver_2010, Waldrop2015}. Just as in the more vanilla scenarios, timely updates to controllers provided on the basis of a single example will need to be verified offline, before shipping, and without the thousands of miles of testing necessary for a typical safety feature. 



%As Brian Soublet of the California DMV pointed out, he knows how to test a 16-year-old's driving skills, but he can't say the same for a car. At the same time, these regulators know that when a death inevitably happensâ€”no amount of %self-driving cars will reduce annual road deaths to zeroâ€”they'll be attacked for allowing unsafe vehicles on the road.
\begin{figure}[b]
	\centering
	\vspace{-10pt}
	\includegraphics[width=\columnwidth]{Figures/tool_single}
	\caption{A single offline execution of the APEX tool calls the local planner associated with the AV in order to generate a reachability problem}
	\label{fig:apex_tool}
\end{figure}

\subsection{APEX: Autonomous vehicle Plan verification \& EXecution}
The APEX tool represents a new approach to solving both the problems of the Urban Challenge and investigating rare events encountered only through on road driving and testing. Unlike other tools capable of verifying controllers for hybrid systems we require almost no abstraction. Most current approaches look at only the behavioral layer and assume perfect implementation of plans at the motion planning layer. Instead, as shown in \figref{apex_tool}, we propose that the behavioral layer is used to generate sequences of problems to be investigated at the level of motion planning and trajectory tracking.  Thus, APEX addresses the safety verification issue by leveraging new results in hybrid systems and reachability analysis \cite{gao2013satisfiability} to convert a brute force search over real intervals (which is intractable) into a set of finite sequences of bounded reachability problems. 

With APEX, we capture the output of trajectory generation and optimization based methods outside of the formal model of the system. Using such information, we generate a sequence of verification problems by running the trajectory through realistic vehicle dynamics and low level controls. The software which runs on the vehicle is used directly for verification with the Robot Operating System (ROS). If a rare event is encountered and recorded by a real vehicle and a new rule or controller is added to the AV it is imperative that the manufacturer have high confidence that the modification will not induce new errors which are not evident in a single trace. APEX can make the most of rare events and scenarios; given a template we could find every possible instantiation and prove it is impossible for solution to make a decision leading to crash. 

The key features of our approach are: (1) Use of realistic planning software which runs on actual vehicles. (2) Modular vehicle model construction which can easily be replaced when new algorithms or alternate vehicle dynamics are necessary. (3) Non-conservative evaluation of safety and liveness at the level of the ego-vehicles actual spatial-temporal evolution. 

Thus, verification of realistic scenarios under all possible configurations over a length of 30-60 seconds is entirely feasible. Using such an approach a manufacturer, regulator, or insurer can begin to build a library of scenarios on which to test new vehicle software or updates made to the behavioral layer made through a reinforcement learner.
 
 \subsection{Open Challenges for Autonomous Vehicle Safety}
\noindent\textbf{1. Scenario Composition for Safe Journeys}
Safety certification will seek to verify that a complete mission, made up of several independently verified scenarios, can be composed to ensure the safety across a journey (i.e. sequence of scenarios). The greatest challenge will be ensuring that the transitions between scenarios will result in safe initial conditions. As not all interactions are observable or captured in formal models, work also needs to be performed on the integration of informal assurance case arguments in a structured manner within APEX. This will also assist in evaluating cooperative and collaborative interactions with the human-in-the-loop.\vspace{0.4pt}
\noindent\textbf{2. Conformance-based Controller testing within the scenario context}
A framework for black-box conformance testing of autonomous vehicle controllers within the context of one or more scenarios is essential for the creation of high confidence code from verified systems and scenarios.\vspace{0.4pt}
\noindent\textbf{3. Property hierarchy for unrealizable specifications}

When a human operator is faced with an unrealizable specification it is common for the driver to knowingly violate a lesser priority safety property i.e. the driver may swerve on to the shoulder lane to avoid a sudden braking vehicle in front. In the context of autonomous driving in general, one can consider that many unrealizable scenarios might arise due to the initialization of the environment. Thus, for each scenario we need to assign priorities to properties such that lower priority properties may be violated to ensure higher priority properties are maintained under extreme scenarios.  
%% \subsection{Verification, learning, ethics, and control}
%In the literature on robot ethics, it remains arguable whether artificial agents without free
%will can truly exhibit moral behavior [1]. However, it seems certain that other road users
%and society will interpret the actions of automated vehicles and the priorities placed by their
%programmers through an ethical lens. Whether in a court of law or the court of public opinion,
%the control algorithms that determine the actions of automated vehicles will be subject
%to close scrutiny after the fact if they result in injury or damage. In a less dramatic, if no
%less important, manner, the way these vehicles move through the social interactions that
%define traffic on a daily basis will strongly influence their societal acceptance. This places
%a considerable responsibility on the programmers of automated vehicles to ensure their
%control algorithms collectively produce actions that are legally and ethically acceptable to
%humans.
		 %\begin{itemize}
		 %	\item Trolley problem
		 %	\begin{itemize}
		 %		\item Level of semantic detail and embellishment added to such scenarios is unrealistic.
		 %		\item The first vehicles to market will simply be programmed with a concept of forward safety.
		 %		\item No manufacturer will ever program an autonomous vehicle to swerve into another vehicle. The pretense of such problems is ridiculous.
		 %		\item Trolley problem does not have a correct solution, instead we should be asking how can we prove that \emph{trolley problems cannot occur based on decisions made by an autonomous agent}
		 %	\end{itemize}
		 %\end{itemize}
 
%% The likely arrival of learned behaviors and the accompanying cost functions which allow the discrimination between multiple feasible strategies will necessitate careful consideration regarding the quantification of desireable robot behaviors. It is easy to personify the \emph{software agent} which operates an AV; naturally, this leads to the consideration of such an agent's ethical duties. It is not clear whether such software can truly exhibit ethical behavior or rather simply mimic the instructions of the designer. Nevertheless, \quotes{it seems certain that other road users and society will interpret the actions of automated vehicles and the priorities placed by their programmers through an ethical lens} \cite{maurer2015autonomes}. In order to improve the safety, efficacy, and percieved morals of AVs we propose 3 areas of promising future research: 
%% \begin{itemize}
%%	 \item Automatic verification of learned behaviors and cost functions
%%	 \item Hierarchical property satisfaction and instantiation of temporal logic constraints in a model predictive control framework
%%	 \item Online verification of behavioral plans \cite{wei2014behavioral} over a range of 5-10 seconds
%% \end{itemize}
 

%% We have already argued that verification of learned behaviors and cost functions is necessary; we propose that such activities should be fully \emph{automated} in manner similar to static verification of source code. Before an update is released it will be subjected to an ever increasing battery of common verification scenarios. Secondly, we intuit that describing vehicle actions as ethical implies that there exists a ranking function over potential behaviors; if vehicle specifications are described hierarchically we can actually dictate and examine the ethics of a particular AV. For example, it may be desirable that only in a near crash situation the AV disregards the speed limit and lane keeping behaviors in order to avoid an accident. Finally, we propose that such \emph{offline} verification techniques in APEX be reimagined and refactored for short-horizon online verification of all potential vehicle actions. It is likely that initial forays into autonomy may require handoffs between human and machine. Studies show \cite{blanco2013human} that a safe handoff requires 5-8 seconds of preparation. Thus, online verification techniques may be used to discover potential system failures and provide fair warning to the driver. 